{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627f0f10-56ac-459f-b6d0-f7c23dac4b3a",
   "metadata": {},
   "source": [
    "### Author: Jesus Cantu Jr.\n",
    "### Last Updated: October 10, 2023\n",
    "\n",
    "There are several transcription services that can be employed in Python, either through direct API calls or through SDKs provided by the service providers, for example: \n",
    "\n",
    "1. **AWS Transcribe**:\n",
    "   - Amazon Transcribe is a service that provides automatic speech recognition (ASR) to convert spoken language into written text. It can be used for various applications, including transcription of audio recordings, voice assistants, and more.\n",
    "   - Python SDK: [AWS SDK for Python (Boto3)](https://aws.amazon.com/sdk-for-python/) \n",
    "\n",
    "2. . **Google Cloud Speech-to-Text**:\n",
    "   - Google's service supports multiple languages and offers features like automatic punctuation, speaker diarization, and recognition of specific words or phrases.\n",
    "   - Python SDK: [Google Cloud Client Library for Python](https://cloud.google.com/python/docs/reference/speech/latest)\n",
    "\n",
    "3. **IBM Watson Speech to Text**:\n",
    "   - IBM's Watson Speech to Text supports various features like keyword spotting, speaker labels, and custom language models.\n",
    "   - Python SDK: [IBM Watson Developer Cloud Python SDK](https://github.com/watson-developer-cloud/python-sdk)\n",
    "\n",
    "4. **Microsoft Azure Speech Service**:\n",
    "   - Part of Azure Cognitive Services, Microsoft's offering supports real-time continuous recognition and batch transcription.\n",
    "   - Python SDK: [Azure SDK for Python](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/speech)\n",
    "\n",
    "5. **Rev.ai**:\n",
    "   - Rev.ai provides both automated and human-powered transcription services. Their automated API is straightforward to use with Python.\n",
    "   - Python SDK: [Rev.ai Python SDK](https://github.com/revdotcom/revai-python-sdk)\n",
    "\n",
    "6. **Speechmatics**:\n",
    "   - Speechmatics offers transcription services in multiple languages.\n",
    "   - While they don't have an official Python SDK, their RESTful API is easy to use with Python's `requests` library.\n",
    "\n",
    "7. **AssemblyAI**:\n",
    "   - AssemblyAI is another transcription service with a straightforward API.\n",
    "   - They provide [Python examples](https://docs.assemblyai.com/overview/getting-started) in their documentation to help you get started quickly.\n",
    "\n",
    "In this notebook we will be comparing several online speech-to-text systems and their ability to transcribe audio files that include children's voices.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6121592-316d-4f32-b484-67a7e553345f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31c45374-2733-4bdd-8564-64ad9b3f666f",
   "metadata": {},
   "source": [
    "## AWS Transcribe\n",
    "AWS Transcribe Summarize simplifies the process of distilling valuable information from audio and video assets.\n",
    "It leverages machine learning to generate concise and coherent summaries of spoken or recorded information. Users can extract key insights, identify important topics, and create textual summaries from lengthy recordings.\n",
    "\n",
    "Prerequisites:\n",
    "1.  __AWS Account__: An AWS account is required to access [AWS services](https://aws.amazon.com/), including Transcribe. \n",
    "2. __IAM Credentials__: You need AWS Identity and Access Management (IAM) credentials, specifically an Access Key ID and Secret Access Key. These credentials will allow your code to authenticate with AWS services. \n",
    "3. __Python SDK__: Install the AWS SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d220e54-c2aa-4cf5-ba38-c0822d0645a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49387afd-9166-4efb-b415-65a7ca89490d",
   "metadata": {},
   "source": [
    "__Step 1__: Upload the audio file to an `S3 bucket`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9f2d9365-adcf-4c26-ab53-04ee8df5ad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File (AR31_021108a.wav) uploaded to S3 Bucket (speech-to-text-processing).\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import configparser\n",
    "\n",
    "def get_aws_credentials(api_key_file):\n",
    "    \"\"\"Read AWS credentials from a file.\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    try:\n",
    "        config.read(api_key_file)\n",
    "        aws_access_key_id = config.get('AWS', 'aws_access_key_id')\n",
    "        aws_secret_access_key = config.get('AWS', 'aws_secret_access_key')\n",
    "        aws_region = config.get('AWS', 'aws_region')\n",
    "    except configparser.NoSectionError:\n",
    "        print(\"Section 'AWS' not found in the credentials file.\")\n",
    "        return None, None, None\n",
    "    except configparser.NoOptionError as e:\n",
    "        print(f\"Error reading {e.option} from the credentials file.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    return aws_access_key_id, aws_secret_access_key, aws_region\n",
    "\n",
    "def upload_to_s3(local_file_path, bucket_name, s3_file_path):\n",
    "    \"\"\"Upload a local file to an S3 bucket.\"\"\"\n",
    "    aws_access_key_id, aws_secret_access_key, aws_region = get_aws_credentials('aws_credentials.txt')\n",
    "    \n",
    "    if not all([aws_access_key_id, aws_secret_access_key, aws_region]):\n",
    "        print(\"Failed to retrieve AWS credentials.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        s3_client = boto3.client('s3', \n",
    "                                 aws_access_key_id = aws_access_key_id, \n",
    "                                 aws_secret_access_key = aws_secret_access_key, \n",
    "                                 region_name = aws_region)\n",
    "        s3_client.upload_file(local_file_path, bucket_name, s3_file_path)\n",
    "        print(f'File ({local_file_path}) uploaded to S3 Bucket ({bucket_name}).')\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "# Example usage\n",
    "local_file = './original_audio_files/AR31_021108a.wav'\n",
    "api_key_file = 'aws_credentials.txt'\n",
    "bucket = 'speech-to-text-processing'\n",
    "s3_path = f'audio_files/{local_file}'\n",
    "\n",
    "upload_to_s3(local_file, bucket, s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72d3a2-44c0-462e-9b41-5a8fef33033c",
   "metadata": {},
   "source": [
    "__Step 2__: Use `Amazon Transcribe` for Batch Processing\n",
    "\n",
    "Amazon Transcribe is a service that converts audio to text. To transcribe an audio file you've uploaded to S3 using Amazon Transcribe, you'll typically follow these steps:\n",
    "\n",
    "1. Start a transcription job.\n",
    "2. Monitor the status of the transcription job.\n",
    "3. Retrieve the transcription once the job is complete.\n",
    "\n",
    "Let's create a function to transcribe the audio file using Amazon Transcribe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d212ec94-2cd5-4e1c-9530-18536673e833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for transcription job to complete...\n",
      "See Suzanne. I come back. Yeah. Sure. Yeah. Yeah. Oh, all right. Ready? I don't think he's right. Oh. Oh, yeah. Yeah. Yeah. Yeah. We gotta sit on the, oh, no, no, you just hit me in the mouth. Not all the people I know. Come on. Oh, you pooped in your pants. Ray? We didn't make it, did we? Yeah. Yeah, I didn't get to you in time, did she? Yeah. What? You too. Yeah, you're too stinky. That was supposed to go in the peepy pot. No, no, that too was supposed to go in the pot. Uh, what? I, yeah. Yuck. Yeah. Ok. It's, I, ok. Yeah. Oh, yeah. Two where you have to learn how to poop in the pot. Yeah. But, oh, sure. Crap. The po po po, right? Oh. What? No. Screaming love. What? Yeah. Would be poop in the pot. Mama wouldn't have to wipe you, honey. This is a stupid, where were you supposed to poop in the pot? That, uh, ok. Yeah, I guess. What are you doing with your tongue? Yeah. Yeah. She, huh? Yeah. Yeah. Yeah. You didn't pee pee in the pot. You pooped in your pants? That's not good. Yeah. Yeah, I love that. Yeah. Is broken. He's a sticker and he's, he's broke. All right. Thank you. Yeah. Cute. Yes. Yes. Yeah. Yes. I just for you, you, your shit. Yeah. Yeah. That's, it's fucking. Yeah.\n",
      "\n",
      "Transcription saved to ./audio_transcripts/AWS_AR31_021108a.wav_transcription.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def start_transcription_job(s3_uri, job_name, region, language_code = 'en-US'):\n",
    "    \"\"\"\n",
    "    Start a transcription job with Amazon Transcribe.\n",
    "    \n",
    "    Args:\n",
    "    - s3_uri (str): The S3 URI of the audio file.\n",
    "    - job_name (str): A unique name for the transcription job.\n",
    "    - region (str): AWS region for the Transcribe service.\n",
    "    - language_code (str): The language code for the input audio. Default is 'en-US'.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The transcription text if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    # Initialize the boto3 client for Transcribe\n",
    "    transcribe_client = boto3.client('transcribe', region_name = region)\n",
    "    \n",
    "    try:\n",
    "        # Start transcription job\n",
    "        response = transcribe_client.start_transcription_job(\n",
    "            TranscriptionJobName = job_name,\n",
    "            Media = {'MediaFileUri': s3_uri},\n",
    "            MediaFormat = 'wav',\n",
    "            LanguageCode = 'en-US',\n",
    "            Settings = {\n",
    "                'ShowSpeakerLabels': True,\n",
    "                'MaxSpeakerLabels': 2  # Change based on the number of speakers in your audio\n",
    "            }\n",
    "        )\n",
    "       \n",
    "        # Wait for the transcription job to complete\n",
    "        while True:\n",
    "            status = transcribe_client.get_transcription_job(TranscriptionJobName = job_name)\n",
    "            if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "                break\n",
    "            print(\"Waiting for transcription job to complete...\")\n",
    "            time.sleep(30)  # Wait for 30 seconds before checking the status again\n",
    "        \n",
    "        # If the transcription job completed successfully, retrieve and return the transcript\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] == 'COMPLETED':\n",
    "            transcript_uri = status['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "            response = requests.get(transcript_uri)\n",
    "            transcript_data = response.json()\n",
    "            return transcript_data['results']['transcripts'][0]['transcript']\n",
    "        else:\n",
    "            print(\"Transcription job failed.\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error starting transcription job: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "s3_uri = f's3://{bucket}/{s3_path}'\n",
    "job_name = f'aws_transcription_{local_file.split(\".\")[0]}_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "region = 'us-east-2'  # Bucket region\n",
    "\n",
    "transcript = start_transcription_job(s3_uri, job_name, region)\n",
    "print(transcript)\n",
    "\n",
    "# Save the transcription to a text file\n",
    "output_file = f\"./generated_audio_transcripts/AWS_{local_file}_transcription.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(transcript)\n",
    "\n",
    "print(f\"\\nTranscription saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e97ac-a917-4dfb-a372-69ada9b89dcf",
   "metadata": {},
   "source": [
    "This script initializes a transcription job, waits for it to complete, then retrieves and saves the transcription. Amazon Transcribe's accuracy can be influenced by a variety of factors, including audio quality, speaker accents, background noise, and the complexity of the content. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4031e-77eb-43ec-a532-cb5ca2b0078c",
   "metadata": {},
   "source": [
    "## Google Cloud Speech-to-Text \n",
    "`Google Cloud Speech-to-Text` is a machine learning-powered service by Google Cloud that converts spoken language into text. It supports over 120 languages, offers both real-time and batch processing, and includes features like noise robustness, speaker diarization, automatic punctuation, and word-level confidence scoring.\n",
    "\n",
    "Prerequisites:\n",
    "1. __Set Up Google Cloud SDK and Credentials__:\n",
    "- Ensure you've set up the Google Cloud SDK on your machine.\n",
    "- Create a service account in the Google Cloud Console and download the JSON key.\n",
    "- Set the environment variable GOOGLE_APPLICATION_CREDENTIALS to the path of the downloaded service account key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "002980f5-d480-4ba6-ad49-bca8cfd522fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"path_to_your_service_account_key.json\"\n",
    "print('Google Application Credentails saved succesfully as an environmental variable!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f358f3db-968f-4c98-bae9-499a3066bd6e",
   "metadata": {},
   "source": [
    "2. __Install the Google Cloud Speech Library__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac64cd5-051a-40a6-bef5-1f009f78393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade google-cloud-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ce40a-ccf9-4ac7-812e-eec1e2259663",
   "metadata": {},
   "source": [
    "__Transcribe audio file using Google Cloud Speech-to-Text__: This code uses the `Google Cloud Speech-to-Text API` to transcribe an audio file stored in Google Cloud Storage to text and saves the transcription to a text file. It provides flexibility to specify the language and enable/disable speaker diarization as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8685f06-ca7c-467b-ba91-7518839b08d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoe shine\n",
      " PB\n",
      " OPP Pride\n",
      " you just hit me in the mouth\n",
      " oh\n",
      " you pooped in your pants red\n",
      " we didn't make it did we\n",
      " yeah\n",
      " can you say hi Josh, didn't get to you in time yeah you too stinky\n",
      " That was supposed to go in the pee pee pot\n",
      " no\n",
      " that too was supposed to go in the pot shoe shoe shoe\n",
      "yuck\n",
      " 2\n",
      " ray you have to learn how to poop in the pot yeah\n",
      " poo poo pie\n",
      " Peppa Pig Peppa Pig\n",
      " no screaming\n",
      " if you poop in the pot Mama wouldn't have to wipe you honey\n",
      " where were you supposed to poop in the pot\n",
      " yeah\n",
      " yeah\n",
      " pee pee but I'm good yeah\n",
      " yeah but he's broke\n",
      " all right\n",
      " yeah cute\n",
      " yeah yeah\n",
      " YouTube\n",
      " tires\n",
      " yeah\n",
      "\n",
      "\n",
      "Transcription saved to ./audio_transcripts/Google_API_AR31_021108a.wav_transcription.txt\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from google.cloud.speech_v1p1beta1 import types\n",
    "\n",
    "def transcribe_google_speech_to_text_gcs(gcs_uri, language = \"en-US\", enable_speaker_diarization = True):\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    audio = types.RecognitionAudio(uri = gcs_uri)\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding = types.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz = 16000,\n",
    "        language_code = language,\n",
    "        enable_speaker_diarization = enable_speaker_diarization\n",
    "    )\n",
    "\n",
    "    # Using the long-running recognize method\n",
    "    operation = client.long_running_recognize(config = config, audio = audio)\n",
    "\n",
    "    # Waiting for the operation to complete (this might take some time depending on the audio length)\n",
    "    response = operation.result(timeout = 3600)  # wait for a maximum of 1 hour\n",
    "\n",
    "    # Extracting and returning the transcription\n",
    "    transcription = \"\"\n",
    "    for result in response.results:\n",
    "        transcription += result.alternatives[0].transcript + \"\\n\"\n",
    "    \n",
    "    return transcription\n",
    "\n",
    "# Call the function using the GCS URI of your audio file\n",
    "gcs_uri = \"gs://sample-voice-recordings/audio_files/AR31_021108a.wav\"\n",
    "transcription = transcribe_google_speech_to_text_gcs(gcs_uri, enable_speaker_diarization = False)\n",
    "\n",
    "# Save the transcription to a text file\n",
    "output_file = f\"./generated_audio_transcripts/Google_API_{file_path}_transcription.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(transcription)\n",
    "\n",
    "print(transcription)\n",
    "print(f\"\\nTranscription saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28492bbb-49e5-4cad-b65f-8e6ddd77435a",
   "metadata": {},
   "source": [
    "In the previous code, the audio file was uploaded to the Google Cloud Storage (GCS) bucket directly using the Google Cloud Console. However, we can upload files and transcribe them, with punctuation and diarization, using Python: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a63b8ac-ea7d-4cfe-9bce-6e36adfb0915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading AR31_021108a.wav to GCS Bucket: sample-voice-recordings...\n",
      "\n",
      "File audio_files/AR31_021108a.wav already exists. Skipping upload.\n",
      "Transcribing with punctuation and diarization...\n",
      "\n",
      "Transcription saved to ./audio_transcripts/Google_API_AR31_021108a_transcription_2.txt\n",
      "Transcription:\n",
      "Speaker 0: Shoe shine.\n",
      "Speaker 0: PB.\n",
      "Speaker 0: OPP Pride.\n",
      "Speaker 0: You just hit me in the mouth.\n",
      "Speaker 0: Oh,\n",
      "Speaker 0: you pooped in your pants red?\n",
      "Speaker 0: We didn't make it, did we?\n",
      "Speaker 0: Yeah.\n",
      "Speaker 0: Can you say hi? Josh, didn't get to you in time. Yeah, you too stinky.\n",
      "Speaker 0: That was supposed to go in the pee pee pot.\n",
      "Speaker 0: No.\n",
      "Speaker 0: That too was supposed to go in the pot, shoe, shoe shoe.\n",
      "Speaker 0: Yuck.\n",
      "Speaker 0: 2.\n",
      "Speaker 0: Ray, you have to learn how to poop in the pot. Yeah.\n",
      "Speaker 0: Poo, poo pie.\n",
      "Speaker 0: Peppa Pig Peppa Pig.\n",
      "Speaker 0: No screaming.\n",
      "Speaker 0: If you poop in the pot, Mama wouldn't have to wipe you honey.\n",
      "Speaker 0: Where were you supposed to poop in the pot?\n",
      "Speaker 0: Yeah.\n",
      "Speaker 0: Yeah.\n",
      "Speaker 0: Pee pee but I'm good. Yeah.\n",
      "Speaker 0: Yeah, but he's broke.\n",
      "Speaker 0: All right.\n",
      "Speaker 0: Yeah, cute.\n",
      "Speaker 0: Yeah. Yeah.\n",
      "Speaker 0: YouTube.\n",
      "Speaker 0: Tires.\n",
      "Speaker 0: Yeah.\n",
      "Speaker 1: Shoe shine. PB. OPP Pride. You just hit me in the mouth. Oh, you pooped in your pants red? We didn't make it, did we? Yeah. Can you say hi? Josh, didn't get to you in time. Yeah, you too stinky. That was supposed to go in the pee pee pot. No. That too was supposed to go in the pot, shoe, shoe shoe. Yuck. 2. Ray, you have to learn how to poop in the pot. Yeah. Poo, poo pie. Peppa Pig Peppa Pig. No screaming. If you poop in the pot, Mama wouldn't have to wipe you honey. Where were you supposed to poop in the pot? Yeah. Yeah. Pee pee but I'm good. Yeah. Yeah, but he's broke. All right. Yeah, cute. Yeah. Yeah. YouTube. Tires. Yeah.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "from google.cloud import storage\n",
    "from google.cloud import speech\n",
    "from num2words import num2words\n",
    "\n",
    "def measure_sample_rate(local_file):\n",
    "    with sf.SoundFile(local_file, \"r\") as sound_file:\n",
    "        sample_rate = sound_file.samplerate\n",
    "    return sample_rate\n",
    "\n",
    "\n",
    "def upload_audio_to_gcs(local_file, gcs_bucket, gcs_filename):\n",
    "    print(f\"Uploading {local_file} to GCS Bucket: {gcs_bucket}...\")\n",
    "    print()\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(gcs_bucket)\n",
    "    blob = bucket.blob(gcs_filename)\n",
    "\n",
    "    if blob.exists():\n",
    "        print(f\"File {gcs_filename} already exists. Skipping upload.\")\n",
    "    else:\n",
    "        blob.upload_from_filename(local_file)\n",
    "        print(f\"File {gcs_filename} uploaded successfully.\")\n",
    "\n",
    "    return f\"gs://{gcs_bucket}/{gcs_filename}\"\n",
    "\n",
    "def transcribe_audio(gcs_uri, convert_numeric_to_text = True, sample_rate = None,\n",
    "                     enable_diarization = True, min_num_speaker = None, max_num_speaker = None):\n",
    "    print(f\"Transcribing with punctuation and diarization...\")\n",
    "    print()\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # Configure the audio settings\n",
    "    audio = speech.RecognitionAudio(uri = gcs_uri)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz = sample_rate,\n",
    "        language_code = \"en-US\",\n",
    "        enable_automatic_punctuation = True,\n",
    "        enable_word_time_offsets = True,\n",
    "        diarization_config = speech.SpeakerDiarizationConfig(\n",
    "            enable_speaker_diarization = enable_diarization,\n",
    "            min_speaker_count = min_num_speaker,\n",
    "            max_speaker_count = max_num_speaker,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Perform the asynchronous transcription\n",
    "    operation = client.long_running_recognize(config = config, audio = audio)\n",
    "    response = operation.result()\n",
    "\n",
    "    # Extract the transcriptions with speaker labels\n",
    "    transcriptions = []\n",
    "    for result in response.results:\n",
    "        alternative = result.alternatives[0]\n",
    "        words = []\n",
    "        for word_info in alternative.words:\n",
    "            word = word_info.word\n",
    "            if convert_numeric_to_text and word.isdigit():\n",
    "                if int(word) < 10:\n",
    "                    word = num2words(int(word))\n",
    "                else:\n",
    "                    word = num2words(int(word), lang = 'en')\n",
    "            words.append(word)\n",
    "        speaker_label = result.alternatives[0].words[0].speaker_tag\n",
    "        transcriptions.append({\"transcript\": \" \".join(words), \"speaker_label\": speaker_label})\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "def save_transcription(transcription, text_filename):\n",
    "    with open(text_filename, \"w\") as f:\n",
    "        f.write(f\"Speaker {transcription['speaker_label']}: {transcription['transcript']}\\n\")\n",
    "\n",
    "# Specify the full path to your audio file\n",
    "audio_file = \"./original_audio_files/AR31_021108a.wav\"\n",
    "\n",
    "# Measure the sample rate of the audio file\n",
    "sample_rate = measure_sample_rate(audio_file)\n",
    "\n",
    "# Specify your GCS bucket and folder\n",
    "gcs_bucket = \"sample-voice-recordings\"  \n",
    "gcs_folder = \"audio_files\"  \n",
    "\n",
    "# Specify the text folder where transcriptions will be saved\n",
    "text_folder = \"./generated_audio_transcripts\" \n",
    "\n",
    "gcs_filename = os.path.join(gcs_folder, os.path.basename(audio_file))\n",
    "gcs_uri = upload_audio_to_gcs(audio_file, gcs_bucket, gcs_filename)\n",
    "sample_rate = measure_sample_rate(audio_file)\n",
    "transcriptions = transcribe_audio(gcs_uri, convert_numeric_to_text = True, sample_rate = sample_rate,\n",
    "                                  enable_diarization = True, min_num_speaker = 1, max_num_speaker = 2)\n",
    "\n",
    "# Generate the output file name\n",
    "audio_file_name = os.path.splitext(os.path.basename(audio_file))[0]  # Extract the base name without extension\n",
    "output_file_name = f\"Google_API_{audio_file_name}_transcription_2.txt\"\n",
    "text_filename = os.path.join(text_folder, output_file_name)\n",
    "\n",
    "\n",
    "# Save the transcription to a text file\n",
    "with open(text_filename, 'w') as f:\n",
    "    for transcription in transcriptions:\n",
    "        f.write(f\"Speaker {transcription['speaker_label']}: {transcription['transcript']}\\n\")\n",
    "\n",
    "print(\"Transcription saved to\", text_filename)\n",
    "\n",
    "# Print the transcriptions\n",
    "print(\"Transcription:\")\n",
    "for transcription in transcriptions:\n",
    "    print(f\"Speaker {transcription['speaker_label']}:\", transcription['transcript'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a6f19-4b7a-4196-a23f-c027afb243de",
   "metadata": {},
   "source": [
    "This code begins by uploading a specified local audio file to a GCS bucket and folder. The script then measures the sample rate of the audio file using the `measure_sample_rate` function. Next, it utilizes the `Google Cloud Speech-to-Text API` for transcription, offering features like converting numeric digits to text, enabling speaker diarization, and specifying the range of speakers. The resulting transcriptions, complete with speaker labels, are saved to a text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6619e-c7c8-4e48-86f4-0ae02a0f21fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42c3f95-9892-4aa4-a2ed-22c36c9dc7fe",
   "metadata": {},
   "source": [
    "## Microsoft Azure Speech Service\n",
    "`Microsoft Azure Speech Service` offers both real-time continuous recognition and batch transcription. With continuous recognition, the function will start recognition and wait for results to come in continuously until the recognition is stopped. This is better suited for longer audio files.\n",
    "\n",
    "Prerequisites:\n",
    "1. __Azure Subscription__: If you don't have an Azure subscription, you can create a [free account](https://azure.microsoft.com/en-us/free).\n",
    "2. __Speech Service__: Create a Speech service in the Azure portal. Note down the API key and the service region.\n",
    "3. __Python SDK__: Install the Azure SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a38f9df-cc0a-4f3e-976b-4e9094664009",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b302fbf-a887-4f15-bbf5-51e8c5ad94a0",
   "metadata": {},
   "source": [
    "__Transcribing Audio using Microsoft Azure Speech Service__: The transcription result will be printed in real-time as the audio is processed. The continuous recognition mode can be more suitable for longer audio files and can provide more granularity in the results, especially when combined with diarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "358baac0-bcea-458c-bbc1-b61a8af1210b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She shoeshine.\n",
      "Ohh.\n",
      "Yeah. Hmm.\n",
      "Yeah.\n",
      "Hey.\n",
      "Session stopped.\n",
      "Right.\n",
      "Hi.\n",
      "Ohh PP Pride.\n",
      "Yeah, yeah, yeah.\n",
      "Yeah, we gotta sit down, baby. ****.\n",
      "Ohh no, ohh. You just hit me in the mouth.\n",
      "Put on the paper, Anna. Come on.\n",
      "Ohh.\n",
      "You pooped in your pants, Ray.\n",
      "We didn't make it, did we? No.\n",
      "Yeah. Can you say shoot? Yeah, shoot. Ohh.\n",
      "Mama didn't get to you in time, did she? Yeah.\n",
      "What to get Yeah, you too stinky.\n",
      "That was supposed to go in the pee pee pot.\n",
      "Ohh no.\n",
      "That, too, was supposed to go in a pot.\n",
      "What? Not I shoot. Yeah. Yuck. Yeah. OK.\n",
      "Choo Choo.\n",
      "She.\n",
      "Yeah.\n",
      "I.\n",
      "Who?\n",
      "Where you have to learn how to poop in a pot. Yeah, she.\n",
      "But.\n",
      "Crap.\n",
      "Poo poo pot.\n",
      "\n",
      "Bam, bam, bam, bam bam bam.\n",
      "Ohh.\n",
      "No screaming.\n",
      "Wow.\n",
      "Ohh.\n",
      "Yeah.\n",
      "If you poop in the pot, Mama wouldn't have to.\n",
      "Why?\n",
      "You honey.\n",
      "Well, this is a good thing.\n",
      "Where were you supposed to poop?\n",
      "In the pot.\n",
      "I.\n",
      "Yeah.\n",
      "Yeah, yeah.\n",
      "Yeah.\n",
      "Yeah.\n",
      "What are you doing with your tongue?\n",
      "Yeah.\n",
      "Please.\n",
      "Thank you.\n",
      "Hey.\n",
      "Run pee pee bag away.\n",
      "So you didn't pee? Pee in the pot? Choose. You pooped in your pants. Yeah. That's not good. Yeah.\n",
      "Yeah, that's cool, man.\n",
      "Yeah, but yeah.\n",
      "And he's a sticker and he's.\n",
      "He's broke.\n",
      "It didn't.\n",
      "Alright.\n",
      "Yeah, cute.\n",
      "Ammo.\n",
      "Alright, yeah, yeah. Ohh.\n",
      "Oh, oh.\n",
      "Yeah, yeah, that's Elmo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.speech.SpeechRecognizer at 0x123764e50>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import time\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig, ResultReason, OutputFormat\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='transcription.log', level=logging.INFO)\n",
    "\n",
    "def read_subscription_key_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.readline().strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading subscription key from file: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def transcribe_audio_continuous(file_path, subscription_key, service_region):\n",
    "    try:\n",
    "        # Set up the Azure Speech configuration\n",
    "        speech_config = SpeechConfig(subscription=subscription_key, region=service_region)\n",
    "        speech_config.request_word_level_timestamps()\n",
    "        speech_config.output_format = OutputFormat.Detailed\n",
    "\n",
    "        # Configure the audio source\n",
    "        audio_config = AudioConfig(filename=file_path)\n",
    "\n",
    "        # Initialize the speech recognizer\n",
    "        recognizer = SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "        done = False\n",
    "\n",
    "        def stop_cb(evt):\n",
    "            nonlocal done\n",
    "            done = True\n",
    "\n",
    "        # Connect callbacks to the events fired by the recognizer\n",
    "        recognizer.recognized.connect(lambda evt: print(evt.result.text))\n",
    "        recognizer.session_stopped.connect(stop_cb)\n",
    "        recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "        # Start continuous recognition\n",
    "        recognizer.start_continuous_recognition()\n",
    "        while not done:\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        # Stop continuous recognition\n",
    "        recognizer.stop_continuous_recognition()\n",
    "\n",
    "        return recognizer\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during transcription: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./original_audio_files/AR31_021108a.wav\"\n",
    "subscription_key_file = \"azure_credentials.txt\"\n",
    "subscription_key = read_subscription_key_from_file(subscription_key_file)\n",
    "service_region = \"eastus\"  # Azure Service Region\n",
    "\n",
    "transcribe_audio_continuous(file_path, subscription_key, service_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1796a00f-52a4-4808-9d10-34964095ddc1",
   "metadata": {},
   "source": [
    "__TODO__: Save the transcription to a text file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50cac7-86ec-4875-846c-0bf794e37037",
   "metadata": {},
   "source": [
    "__Transcribing Audio using Microsoft Azure Speech Service__: Here's how you can modify the function to include diarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cf0b075-45e0-4b92-a846-2c05f03ae568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session stopped.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig, ResultReason, OutputFormat\n",
    "\n",
    "def read_subscription_key_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the Azure subscription key from a file.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the file containing the subscription key.\n",
    "\n",
    "    Returns:\n",
    "    - str: The subscription key.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.readline().strip()\n",
    "\n",
    "def transcribe_audio_continuous_with_diarization(file_path, subscription_key, service_region):\n",
    "    \"\"\"\n",
    "    Transcribe audio from a file using Azure Speech Service's continuous recognition with diarization.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the audio file.\n",
    "    - subscription_key (str): Azure Speech Service subscription key.\n",
    "    - service_region (str): Azure service region (e.g., 'westus').\n",
    "\n",
    "    Returns:\n",
    "    - None: Prints the transcription result with speaker labels.\n",
    "    \"\"\"\n",
    "    # Set up the Azure Speech configuration\n",
    "    speech_config = SpeechConfig(subscription = subscription_key, region = service_region)\n",
    "    speech_config.request_word_level_timestamps()\n",
    "    speech_config.output_format = OutputFormat.Detailed\n",
    "    speech_config.set_property_by_name(\"EnableSpeakerDiarization\", \"true\")\n",
    "    speech_config.set_property_by_name(\"SpeakerCount\", \"2\")  # Assumes 2 speakers in the audio, adjust if needed\n",
    "\n",
    "    # Configure the audio source\n",
    "    audio_config = AudioConfig(filename = file_path)\n",
    "\n",
    "    # Initialize the speech recognizer\n",
    "    recognizer = SpeechRecognizer(speech_config = speech_config, audio_config = audio_config)\n",
    "\n",
    "    done = False\n",
    "\n",
    "    # Connect callbacks to the events fired by the recognizer\n",
    "    def recognized_handler(evt):\n",
    "        print(f\"Speaker {evt.result.properties['Property_SpeakerId']}: {evt.result.text}\")\n",
    "\n",
    "    def session_stopped_handler(evt):\n",
    "        nonlocal done\n",
    "        print(\"Session stopped.\")\n",
    "        done = True\n",
    "\n",
    "    def canceled_handler(evt):\n",
    "        nonlocal done\n",
    "        print(f\"Speech Recognition canceled: {evt.reason}. Error details: {evt.error_details}\")\n",
    "        done = True\n",
    "\n",
    "    recognizer.recognized.connect(recognized_handler)\n",
    "    recognizer.session_stopped.connect(session_stopped_handler)\n",
    "    recognizer.canceled.connect(canceled_handler)\n",
    "\n",
    "    # Start continuous recognition\n",
    "    recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(5)\n",
    "\n",
    "    # Stop continuous recognition\n",
    "    recognizer.stop_continuous_recognition()\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./original_audio_files/AR31_021108a.wav\"\n",
    "subscription_key_file = \"azure_credentials.txt\"\n",
    "subscription_key = read_subscription_key_from_file(subscription_key_file)\n",
    "service_region = \"eastus\"  # Azure Service Region\n",
    "\n",
    "transcribe_audio_continuous_with_diarization(file_path, subscription_key, service_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7186a3f0-1a9f-4701-a138-5843d847b193",
   "metadata": {},
   "source": [
    "__TODO__: Diagnose problems with diarization. There might be service limitations; the audio file is long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44639bb8-7425-4602-9c1c-813bf1bba391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c1ccd5b-16f6-4885-b4a4-a1ce76bac049",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rev.avi\n",
    "\n",
    "`Rev.ai` is an automatic speech recognition (ASR) service offered by Rev.com, renowned for its transcription and captioning offerings. The service converts spoken language into written text using advanced ASR models, ensuring high accuracy. It supports multiple languages, can differentiate between speakers, and provides detailed transcriptions with punctuation, capitalization, and timestamps. The API also offers real-time transcription capabilities through WebSockets and options for content filtering.\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "1. __Rev.ai Account__: Create an account on [Rev.ai](https://www.rev.ai/). Once you sign up, you'll be given an API key.\n",
    "2. __Python Requests Library__: Install the requests library, which makes it easy to call the API:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a45e99-5752-433e-8eea-deeb7c991a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c3fea-1d40-43c2-80a2-6c83f9a01049",
   "metadata": {},
   "source": [
    "__Transcribing Audio with Rev.ai API__: The code provides an end-to-end process for transcribing a local audio file using the Rev.ai API. It submits the audio file, checks the transcription status at regular intervals, fetches the transcription once complete, and then saves it to a file.\n",
    "\n",
    "Speaker diarization is automatically performed on audio files that contain multiple speakers. When the transcription is returned, different speakers are labeled in the output, allowing you to determine which segments of the transcription correspond to which speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d8cbe38-43de-43dc-aa3c-4f533fe6443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job submitted successfully. Job ID: 7UgQcaSbXMh7r0AQ\n",
      "Job is still being processed. Waiting for another 30 seconds.\n",
      "Job is still being processed. Waiting for another 30 seconds.\n",
      "Job is still being processed. Waiting for another 30 seconds.\n",
      "Transcription:\n",
      "\n",
      "Speaker 0    00:00:15    Yeah, she pee.  \n",
      "Speaker 2    00:00:21    Alright, Ray,  \n",
      "Speaker 1    00:00:22    Sit  \n",
      "Speaker 2    00:00:22    On the pee pee pot. Oh, peepee pot? Yeah, yeah, yeah, yeah. We gotta sit on the peepee  \n",
      "Speaker 1    00:00:39    Pot.  \n",
      "Speaker 2    00:00:41    Oh no. Ow. You just hit me in the mouth.  \n",
      "Speaker 0    00:00:45    Sit on the pee pee pot  \n",
      "Speaker 2    00:00:46    <laugh>. I know. Come on. Oh, you pooped in your pants, Ray. We didn't make it, did we?  \n",
      "Speaker 0    00:01:03    No, it my baby pot.  \n",
      "Speaker 2    00:01:06    Yeah. Did you stay with  \n",
      "Speaker 0    00:01:08    I chew? Yeah,  \n",
      "Speaker 2    00:01:10    I chew.  \n",
      "Speaker 0    00:01:11    I  \n",
      "Speaker 2    00:01:12    Momma didn't get to you in time, did she?  \n",
      "Speaker 0    00:01:15    Yeah. What? Too stinking? Yeah,  \n",
      "Speaker 2    00:01:20    You're too stinky. That was supposed to go in the peepee pot.  \n",
      "Speaker 0    00:01:26    Oh no.  \n",
      "Speaker 2    00:01:29    That too was supposed to go in the pot.  \n",
      "Speaker 0    00:01:32    Oh,  \n",
      "Speaker 2    00:01:34    What in the it?  \n",
      "Speaker 0    00:01:36    A shoe?  \n",
      "Speaker 2    00:01:37    Yeah. Yuck.  \n",
      "Speaker 0    00:01:39    Yeah. It's a shoe  \n",
      "Speaker 2    00:01:43    Pew.  \n",
      "Speaker 0    00:01:46    Ah, ah,  \n",
      "Speaker 2    00:01:53    Yuck.  \n",
      "Speaker 0    00:01:58    Ah. Who?  \n",
      "Speaker 2    00:02:04    Ray, you have to learn how to poop in the pot.  \n",
      "Speaker 0    00:02:07    Yeah, he poop. Poop. Poop. Prep.  \n",
      "Speaker 2    00:02:16    Poo poop. Hot. No. Screaming.  \n",
      "Speaker 1    00:02:59    I cat.  \n",
      "Speaker 2    00:03:05    If you poop in the pot, mama wouldn't have to wipe you, honey. Where were you supposed to poop? In the pot.  \n",
      "Speaker 0    00:03:21    That, uh, I poop.  \n",
      "Speaker 2    00:03:45    What are you doing with your tongue?  \n",
      "Speaker 0    00:03:49    Yeah. <inaudible>.  \n",
      "Speaker 2    00:03:56    Hmm? <laugh>  \n",
      "Speaker 0    00:04:02    Pee pee bags over. You didn't pee pee?  \n",
      "Speaker 2    00:04:06    You didn't pee. Pee in the pot.  \n",
      "Speaker 0    00:04:07    Two. You  \n",
      "Speaker 2    00:04:09    Pooped in your pants.  \n",
      "Speaker 0    00:04:10    Yeah.  \n",
      "Speaker 2    00:04:12    That's not good.  \n",
      "Speaker 0    00:04:13    Yeah. Elmo.  \n",
      "Speaker 2    00:04:15    Yeah. That's Elmo.  \n",
      "Speaker 0    00:04:18    Yeah. <inaudible>.  \n",
      "Speaker 2    00:04:21    Yeah. Elmo's broken. He's a sticker and he is. He's broke  \n",
      "Speaker 0    00:04:26    Sticker. It sticks  \n",
      "Speaker 2    00:04:30    All right. Be  \n",
      "Speaker 0    00:04:33    Yeah. Cute. Yeah. Yeah. Is  \n",
      "Speaker 2    00:04:56    That, that's Elma?  \n",
      "Speaker 0    00:04:59    Yeah. \n",
      "\n",
      "\n",
      "Transcription saved to ./audio_transcripts/Revai_API_AR31_021108a.wav_transcription.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def read_api_key_from_file(file_path):\n",
    "    \"\"\"Read the API key from a file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.readline().strip()\n",
    "\n",
    "def submit_file_for_transcription(file_path, api_key):\n",
    "    \"\"\"Submit a local audio file to Rev.ai for transcription.\"\"\"\n",
    "    url = \"https://api.rev.ai/speechtotext/v1/jobs\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'rb') as audio_file:\n",
    "        response = requests.post(url, headers = headers, files = {\"media\": audio_file})\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error submitting file: {response.text}\")\n",
    "        return None\n",
    "\n",
    "    job_details = response.json()\n",
    "    print(f\"Job submitted successfully. Job ID: {job_details['id']}\")\n",
    "    return job_details['id']\n",
    "\n",
    "def check_job_status(job_id, api_key):\n",
    "    \"\"\"Check the status of a transcription job.\"\"\"\n",
    "    url = f\"https://api.rev.ai/speechtotext/v1/jobs/{job_id}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    response = requests.get(url, headers = headers)\n",
    "    return response.json()[\"status\"]\n",
    "\n",
    "def fetch_transcription(job_id, api_key):\n",
    "    \"\"\"Fetch the transcription results for a completed job.\"\"\"\n",
    "    url = f\"https://api.rev.ai/speechtotext/v1/jobs/{job_id}/transcript\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Accept\": \"text/plain\"  # Request plain text transcription\n",
    "    }\n",
    "    response = requests.get(url, headers = headers)\n",
    "    return response.text\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./original_audio_files/AR31_021108a.wav\"\n",
    "api_key_file = \"revai_api_credentials.txt\"\n",
    "api_key = read_api_key_from_file(api_key_file)\n",
    "\n",
    "job_id = submit_file_for_transcription(file_path, api_key)\n",
    "\n",
    "# Poll the API until the transcription is done\n",
    "while True:\n",
    "    status = check_job_status(job_id, api_key)\n",
    "    if status == \"transcribed\":\n",
    "        break\n",
    "    elif status in [\"failed\", \"invalid\"]:\n",
    "        print(\"Transcription failed.\")\n",
    "        exit()\n",
    "    else:\n",
    "        print(\"Job is still being processed. Waiting for another 30 seconds.\")\n",
    "        time.sleep(30)\n",
    "\n",
    "transcription = fetch_transcription(job_id, api_key)\n",
    "\n",
    "# Print the transcription\n",
    "print(\"Transcription:\\n\")\n",
    "print(transcription)\n",
    "\n",
    "# Save the transcription to a text file\n",
    "output_file = f\"./generated_audio_transcripts/Revai_API_{file_path}_transcription.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(transcription)\n",
    "\n",
    "print(f\"\\nTranscription saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2380f39-94cc-41aa-b4af-3ad562771038",
   "metadata": {},
   "source": [
    "__TODO__: Improve speaker diarization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928f4cf-9de4-4863-a264-4850c9435923",
   "metadata": {},
   "source": [
    "__Transcribing Audio with Rev.ai [SDK](https://github.com/revdotcom/revai-python-sdk)__: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f03e45-bae1-44c5-b4fc-65a1b8515f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade rev_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04fa35dc-f7c0-443d-90c2-8df056bb72fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job is still being processed. Waiting for another 60 seconds.\n",
      "Job is still being processed. Waiting for another 60 seconds.\n",
      "Job is still being processed. Waiting for another 60 seconds.\n",
      "Job is still being processed. Waiting for another 60 seconds.\n",
      "Job is still being processed. Waiting for another 60 seconds.\n",
      "Job is still being processed. Waiting for another 60 seconds.\n",
      "Job is still being processed. Waiting for another 60 seconds.\n",
      "Job is still being processed. Waiting for another 60 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob is still being processed. Waiting for another 60 seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# retrieve transcript as text\u001b[39;00m\n\u001b[1;32m     33\u001b[0m transcript_text \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_transcript_text(job\u001b[38;5;241m.\u001b[39mid)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from rev_ai import apiclient\n",
    "import time\n",
    "\n",
    "def read_api_key_from_file(file_path):\n",
    "    \"\"\"Read the API key from a file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.readline().strip()\n",
    "\n",
    "api_key_file = \"revai_api_credentials.txt\"\n",
    "api_key = read_api_key_from_file(api_key_file)\n",
    "file_path = \"./original_audio_files/AR31_021108a.wav\"\n",
    "\n",
    "# create your client\n",
    "client = apiclient.RevAiAPIClient(api_key)\n",
    "\n",
    "# send a local file\n",
    "job = client.submit_job_local_file(file_path)\n",
    "\n",
    "# Poll the API until the transcription is done\n",
    "while True:\n",
    "    job_details = client.get_job_details(job.id)\n",
    "    status = job_details.status\n",
    "    if status == \"transcribed\":\n",
    "        break\n",
    "    elif status in [\"failed\", \"invalid\"]:\n",
    "        print(\"Transcription failed.\")\n",
    "        exit()\n",
    "    else:\n",
    "        print(\"Job is still being processed. Waiting for another 60 seconds.\")\n",
    "        time.sleep(60)\n",
    "\n",
    "# retrieve transcript as text\n",
    "transcript_text = client.get_transcript_text(job.id)\n",
    "print(transcript_text)\n",
    "\n",
    "# retrieve transcript as JSON\n",
    "#transcript_json = client.get_transcript_json(job.id)\n",
    "\n",
    "# retrieve transcript as a Python object\n",
    "# transcript_object = client.get_transcript_object(job.id)\n",
    "\n",
    "# Save the transcription to a text file\n",
    "output_file = f\"./generated_audio_transcripts/Revai_SDK_{file_path}_transcription.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(transcript_text)\n",
    "\n",
    "print(f\"\\nTranscription saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41172e-bb90-46bb-9a52-43d3484ade83",
   "metadata": {},
   "source": [
    "__TODO__: Figure out why SDK takes longer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7115f-24a9-4d9a-b4b8-1bd7501d00f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30352744-a5fc-4570-bf2a-13c720d5e5a1",
   "metadata": {},
   "source": [
    "## AssemblyAI\n",
    "`AssemblyAI` is a company that offers a powerful speech-to-text API, designed to convert spoken language into written text. Their platform is built on top of deep learning models, which are trained on massive amounts of data to provide accurate transcriptions.\n",
    "\n",
    "Prerequisites:\n",
    "1. First, sign up for an account with [AssemblyAI](https://www.assemblyai.com/).\n",
    "2. Once you have an account, you'll be provided with an API key, which you'll need to make requests.\n",
    "\n",
    "__Transcribing Audio with AssemblyAI__: The provided code uses the official `AssemblyAI Python SDK (assemblyai)` to simplify the process of submitting audio files for transcription. The SDK handles many of the underlying details, such as uploading the file, submitting the transcription request, polling for completion, and fetching the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10104bd7-e4f6-4b0b-8358-ae69c3ba1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the SDK\n",
    "! pip install -U assemblyai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8899d62-c887-4caf-8c30-66baf5dbf586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker A: Sushi shine go by she shine. Yeah. She be sheep. All right, ray pot you.\n",
      "Speaker B: Oh, no.\n",
      "Speaker A: Ow.\n",
      "Speaker B: You just hit me in the mouth.\n",
      "Speaker A: Sit on the peepee pot. I know. Come on.\n",
      "Speaker B: Oh, you pooped in your pants. Ray, we didn't make it, did we?\n",
      "Speaker A: No. It's my baby pie.\n",
      "Speaker B: Yeah.\n",
      "Speaker A: Can you stay?\n",
      "Speaker B: Yeah, I chew. Mama didn't get to you in time, did she?\n",
      "Speaker A: Yeah.\n",
      "Speaker B: You're, too, Stinky. That was supposed to go in the peepee pot.\n",
      "Speaker A: Oh, no.\n",
      "Speaker B: That too was supposed to go in the pot, wasn't it?\n",
      "Speaker A: Yeah.\n",
      "Speaker B: Yuck.\n",
      "Speaker A: Yeah.\n",
      "Speaker B: Ray, you have to learn how to poop in the pot. Mama wouldn't have to wipe your honey.\n",
      "Speaker A: Well.\n",
      "Speaker B: Where were you supposed to poop? In the pot.\n",
      "Speaker A: Yeah, wasn't it?\n",
      "Speaker B: What are you doing with your tongue, little yeah.\n",
      "Speaker A: Thank you, peepee bat.\n",
      "Speaker B: You didn't peepee in the pot. You pooped in your pants.\n",
      "Speaker A: Yeah.\n",
      "Speaker B: That's not good.\n",
      "Speaker A: Yeah, that's Elmo. Yeah.\n",
      "Speaker B: Elmo is broken. He's a sticker and he's broke.\n",
      "Speaker A: All right.\n",
      "Speaker B: Feet.\n",
      "Speaker A: Yeah. Cute it. Yeah. Yes. Shoot. Yeah, that's Elmo.\n",
      "\n",
      "Transcription saved to ./audio_transcripts/AssemblyAI_AR31_021108a.wav_transcription.txt\n"
     ]
    }
   ],
   "source": [
    "import assemblyai as aai\n",
    "\n",
    "def read_api_key_from_file(file_path):\n",
    "    \"\"\"Read the API key from a file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.readline().strip()\n",
    "\n",
    "# Set your API key\n",
    "api_key_file = \"assemblyai_api_credentials.txt\"\n",
    "api_key = read_api_key_from_file(api_key_file)\n",
    "aai.settings.api_key = api_key\n",
    "\n",
    "# Path to the audio file\n",
    "file_path = \"./original_audio_files/AR31_021108a.wav\"\n",
    "\n",
    "# Create a transcription configuration with speaker labels enabled\n",
    "config = aai.TranscriptionConfig(speaker_labels=True)\n",
    "\n",
    "# Initialize the transcriber and submit the audio file for transcription\n",
    "transcriber = aai.Transcriber()\n",
    "transcript = transcriber.transcribe(file_path, config=config)\n",
    "\n",
    "# Prepare the transcription text\n",
    "transcription_text = \"\\n\".join([f\"Speaker {utterance.speaker}: {utterance.text}\" for utterance in transcript.utterances])\n",
    "\n",
    "# Print the transcription with speaker labels\n",
    "print(transcription_text)\n",
    "\n",
    "# Save the transcription to a text file\n",
    "output_file = f\"./generated_audio_transcripts/AssemblyAI_{file_path.split('/')[-1]}_transcription.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(transcription_text)\n",
    "\n",
    "print(f\"\\nTranscription saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e97ee-5777-4790-b638-3bb9546747f5",
   "metadata": {},
   "source": [
    "__TODO:__ Use AssemblyAI's [LeMUR](https://www.assemblyai.com/docs/guides/processing-audio-with-llms-using-lemur)  (Leveraging Large Language Models to Understand Recognized Speech) framework to process audio files with an LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c320b-6da4-4a17-beeb-d17cc68834d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
